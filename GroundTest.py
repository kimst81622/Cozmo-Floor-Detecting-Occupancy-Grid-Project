from cozmo_fsm import *

class GroundTest(StateMachineProgram):
  def __init__(self):
    super().__init__(viewer_crosshairs=True, particle_viewer=True)

  def start(self):
    super().start()
    robot.camera.color_image_enabled = True

  class ProjectToGround(StateNode):
    def start(self,event=None):
      super().start(event)
      camera_center = (320/2, 240/2)
      point = self.robot.kine.project_to_ground(*camera_center)
      base_to_world = robot.kine.base_to_link('world')
      world_point = base_to_world.dot(point)
      print('Camera center point is at %4.1f, %4.1f' % (world_point[0], world_point[1]))


      patch_top_left = (140, 100)
      patch_top_right = (180, 100)
      patch_bot_right = (180, 140)
      patch_bot_left = (140, 140)
      
      top_left_point = self.robot.kine.project_to_ground(*patch_top_left)
      top_right_point = self.robot.kine.project_to_ground(*patch_top_right)
      bot_right_point = self.robot.kine.project_to_ground(*patch_bot_right)
      bot_left_point = self.robot.kine.project_to_ground(*patch_bot_left)
      
      base_to_world = robot.kine.base_to_link('world')

      world_top_left_point = base_to_world.dot(top_left_point)
      world_top_right_point = base_to_world.dot(top_right_point)
      world_bot_right_point = base_to_world.dot(bot_right_point)
      world_bot_left_point = base_to_world.dot(bot_left_point)

      print('Top Left', world_top_left_point)
      print('Top Right', world_top_right_point)
      print('Bottom Left', world_bot_left_point)
      print('Bottom Right', world_bot_right_point)

      print('Camera center point is at %4.1f, %4.1f' % (point[0], point[1]))
      print('Top Left', top_left_point)
      print('Top Right', top_right_point)
      print('Bottom Left', bot_left_point)
      print('Bottom Right', bot_right_point)

  class GrabPatch(StateNode):
    def start(self,event=None):
      super().start(event)
      img = np.array(self.robot.world.latest_image.raw_image)
      self.parent.patch = img[115:125, 155:165, :]
      patch2 = cv2.cvtColor(self.parent.patch, cv2.COLOR_RGB2BGR)
      cv2.imshow('patch',patch2)
      cv2.waitKey(0)

  class MatchPatch(StateNode):
    def start(self,event=None):
      super().start(event)
      img = np.array(self.robot.world.latest_image.raw_image)
      sample = img[115:125, 155:165, :]
      diff = ((sample - self.parent.patch).flatten()**2).sum()
      print('Match error =', diff)
      sample2 = cv2.cvtColor(sample, cv2.COLOR_RGB2BGR)
      cv2.imshow('sample',sample2)
      cv2.waitKey(0)

  def setup(self):
      """
        dispatch: StateNode()
        dispatch =TM('p')=> project
        dispatch =TM('g')=> grab
        dispatch =TM('m')=> match
    
        project: self.ProjectToGround() =N=> dispatch
    
        grab: self.GrabPatch() =N=> dispatch
    
        match: self.MatchPatch() =N=> dispatch
    
      """
      
      # Code generated by genfsm on Mon Apr 27 14:30:27 2020:
      
      dispatch = StateNode() .set_name("dispatch") .set_parent(self)
      project = self.ProjectToGround() .set_name("project") .set_parent(self)
      grab = self.GrabPatch() .set_name("grab") .set_parent(self)
      match = self.MatchPatch() .set_name("match") .set_parent(self)
      
      textmsgtrans1 = TextMsgTrans('p') .set_name("textmsgtrans1")
      textmsgtrans1 .add_sources(dispatch) .add_destinations(project)
      
      textmsgtrans2 = TextMsgTrans('g') .set_name("textmsgtrans2")
      textmsgtrans2 .add_sources(dispatch) .add_destinations(grab)
      
      textmsgtrans3 = TextMsgTrans('m') .set_name("textmsgtrans3")
      textmsgtrans3 .add_sources(dispatch) .add_destinations(match)
      
      nulltrans1 = NullTrans() .set_name("nulltrans1")
      nulltrans1 .add_sources(project) .add_destinations(dispatch)
      
      nulltrans2 = NullTrans() .set_name("nulltrans2")
      nulltrans2 .add_sources(grab) .add_destinations(dispatch)
      
      nulltrans3 = NullTrans() .set_name("nulltrans3")
      nulltrans3 .add_sources(match) .add_destinations(dispatch)
      
      return self
